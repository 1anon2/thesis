{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:26.882137800Z",
     "start_time": "2024-02-04T19:01:25.780527700Z"
    }
   },
   "id": "5a61e3af193aeee1",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_og = pd.read_pickle(\"MulTweEmo/datasetPkl/merged_df_with_gold_freq1.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.360456100Z",
     "start_time": "2024-02-04T19:01:26.891489800Z"
    }
   },
   "id": "3348b470e345dd1e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def anonymize_and_fix_amps(tweet):\n",
    "    toks = str(tweet).split()\n",
    "    for idx,t in enumerate(toks):\n",
    "        if t[0] == '@':\n",
    "            toks[idx] = '@USER'\n",
    "        if t == '&amp;':\n",
    "            toks[idx] = '&'\n",
    "    return ' '.join(toks)\n",
    "\n",
    "df_og['tweet'] = df_og['tweet'].apply(anonymize_and_fix_amps)\n",
    "df_gold = df_og[df_og.T_Surprise.isnull() == False]\n",
    "df_gold = df_gold[df_gold.M_gold_multi_label.str.len() != 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.413103800Z",
     "start_time": "2024-02-04T19:01:27.360456100Z"
    }
   },
   "id": "17969024b3eec8d5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_neutral_smt(labels):\n",
    "    new_l=[]\n",
    "    for e in labels:\n",
    "        if e != \"Something else\" and e != \"Neutral\":\n",
    "            new_l.append(e)\n",
    "    return new_l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.413103800Z",
     "start_time": "2024-02-04T19:01:27.409879500Z"
    }
   },
   "id": "7384cac5e83fc064",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_gold['M_gold_multi_label'] = df_gold['M_gold_multi_label'].apply(remove_neutral_smt)\n",
    "df_gold['T_gold_multi_label'] = df_gold['T_gold_multi_label'].apply(remove_neutral_smt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.463563Z",
     "start_time": "2024-02-04T19:01:27.423684300Z"
    }
   },
   "id": "1baa4ec6fbf08652",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "875"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_gold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.466263200Z",
     "start_time": "2024-02-04T19:01:27.432846500Z"
    }
   },
   "id": "f72b8d96a5ba7364",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = df_gold"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.467780800Z",
     "start_time": "2024-02-04T19:01:27.451008700Z"
    }
   },
   "id": "eee48a7031050be4",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "875"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.600036500Z",
     "start_time": "2024-02-04T19:01:27.462271800Z"
    }
   },
   "id": "f7852bc7c690acf",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def replace_string(row):\n",
    "    new_row = []\n",
    "    for item in row:\n",
    "        new_row.append(item.replace('../',''))\n",
    "    return new_row\n",
    "\n",
    "df['path_photos'] = df['path_photos'].apply(replace_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.601198600Z",
     "start_time": "2024-02-04T19:01:27.483141900Z"
    }
   },
   "id": "1405365cbd4f6db5",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "columns = ['tweet','path_photos', 'M_gold_multi_label', 'T_gold_multi_label']\n",
    "df = df.loc[:, columns]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.603429300Z",
     "start_time": "2024-02-04T19:01:27.489882500Z"
    }
   },
   "id": "6cbe062e8175031a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.643754500Z",
     "start_time": "2024-02-04T19:01:27.505817300Z"
    }
   },
   "id": "4c3c0bcc9a2aee1",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = df.explode(['path_photos']).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.644825100Z",
     "start_time": "2024-02-04T19:01:27.522940600Z"
    }
   },
   "id": "b87244aa5e0be901",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = df[:50]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:01:27.647005800Z",
     "start_time": "2024-02-04T19:01:27.550279500Z"
    }
   },
   "id": "d980e76890dfb015",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 20:01:33.274436: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-04 20:01:33.274558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-04 20:01:33.325979: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-04 20:01:33.445444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-04 20:01:35.237619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import tensorflow as tf\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" \n",
    "\n",
    "def extract_and_concatenate(curr_txt, curr_img):\n",
    "    curr_img = Image.open(curr_img)\n",
    "    inputs = processor(text=curr_txt, \n",
    "                       images=curr_img, \n",
    "                       return_tensors='pt', \n",
    "                       padding='max_length', \n",
    "                       truncation=True)\n",
    "    inputs = inputs\n",
    "    outputs = model(**inputs)\n",
    "    image_features = outputs.image_embeds\n",
    "    text_features = outputs.text_embeds\n",
    "    \n",
    "    concat = torch.cat((image_features, text_features), dim=1)\n",
    "    #concat = tf.concat(values=[image_features, text_features], axis=1)\n",
    "    return concat\n",
    "\n",
    "images = df.path_photos.values\n",
    "texts = df.tweet.values\n",
    "\n",
    "X = []\n",
    "\n",
    "for idx, p in enumerate(images):\n",
    "    curr_img = images[idx]\n",
    "    curr_txt = texts[idx]\n",
    "    print(idx)\n",
    "    conc = extract_and_concatenate(curr_txt, curr_img)\n",
    "    X.append(conc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:02:10.768622500Z",
     "start_time": "2024-02-04T19:01:27.558496200Z"
    }
   },
   "id": "c9d4cfcd6181efab",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "X = np.squeeze(np.asarray([i.detach().numpy() for i in X]))\n",
    "\n",
    "y = df['T_gold_multi_label']\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "yt = mlb.fit_transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T19:35:09.349677700Z",
     "start_time": "2024-02-04T19:35:09.253403300Z"
    }
   },
   "id": "3ce9a1bca7fba7e6",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(50, 50)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(yt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "805681621e315a18",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, schedules, SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, LSTM\n",
    "import tensorflow as tf \n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "#keras custom f1_score metric\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\"\"\"\n",
    "\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\"\"\"\n",
    "\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "        \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yt, test_size=0.15,\n",
    "                                                   shuffle=True, random_state=42)\n",
    "\n",
    "model_1 = Sequential(name=\"ANN-1\")\n",
    "model_1.add(Input(shape=(1024,), name='input'))  # is 512 when using only visual or textual embeddings\n",
    "                                 # & 1024 when using multimodal embeddings\n",
    "model_1.add(Dense(400, activation='relu', name=\"feedforward_1\"))\n",
    "model_1.add(Dropout(0.4, name='dropout_0.4'))\n",
    "\n",
    "model_1.add(Dense(200, activation='relu', name=\"feedforward_2\"))\n",
    "model_1.add(Dropout(0.2, name=\"dropout_0.2\"))\n",
    "model_1.add(Dense(8, activation='sigmoid', name=\"output\"))\n",
    "model_1.output_shape\n",
    "\n",
    "#opt = tf.keras.optimizers.SGD(learning_rate=0.002, nesterov=True)\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[f1, \"accuracy\"],)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T20:10:42.082034700Z",
     "start_time": "2024-02-04T20:10:41.916042300Z"
    }
   },
   "id": "7759835d757463be",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/picomachine/.virtualenvs/thesis/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 21:11:11.029415: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:504] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-12.2\n",
      "  /usr/local/cuda\n",
      "  /home/picomachine/.virtualenvs/thesis/lib/python3.10/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/picomachine/.virtualenvs/thesis/lib/python3.10/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2024-02-04 21:11:11.186616: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:11.210784: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:11.210928: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:11.243103: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:11.243259: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.094785: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.094917: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.117235: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.117345: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.117388: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.117508: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.142540: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.142687: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.142767: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.142857: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.167596: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.167770: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.167879: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.167990: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.188416: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.188532: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.188583: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.188790: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.215470: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.215599: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.215773: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.215906: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.240260: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.240444: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.241027: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.241198: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.265282: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.265472: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.265884: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.266014: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.291473: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.291587: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.291606: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:110] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-02-04 21:11:13.291733: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:13.330505: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-04 21:11:13.330660: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-02-04 21:11:14.075221: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:542] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "error: libdevice not found at ./libdevice.10.bc\n",
      "2024-02-04 21:11:14.078752: E tensorflow/compiler/mlir/tools/kernel_gen/tf_framework_c_interface.cc:207] INTERNAL: Generating device code failed.\n",
      "2024-02-04 21:11:14.079860: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Exception encountered when calling layer 'output' (type Dense).\n\n{{function_node __wrapped__Sigmoid_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sigmoid] name: \n\nCall arguments received by layer 'output' (type Dense):\n  • inputs=tf.Tensor(shape=(4, 200), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m BATCH \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(X_train)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mmodel_1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.15\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m          \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m          \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mes\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m          \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/thesis/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/.virtualenvs/thesis/lib/python3.10/site-packages/keras/src/backend.py:5915\u001B[0m, in \u001B[0;36msigmoid\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m   5903\u001B[0m \u001B[38;5;129m@keras_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras.backend.sigmoid\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   5904\u001B[0m \u001B[38;5;129m@tf\u001B[39m\u001B[38;5;241m.\u001B[39m__internal__\u001B[38;5;241m.\u001B[39mdispatch\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[1;32m   5905\u001B[0m \u001B[38;5;129m@doc_controls\u001B[39m\u001B[38;5;241m.\u001B[39mdo_not_generate_docs\n\u001B[1;32m   5906\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msigmoid\u001B[39m(x):\n\u001B[1;32m   5907\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Element-wise sigmoid.\u001B[39;00m\n\u001B[1;32m   5908\u001B[0m \n\u001B[1;32m   5909\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5913\u001B[0m \u001B[38;5;124;03m        A tensor.\u001B[39;00m\n\u001B[1;32m   5914\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5915\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msigmoid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5916\u001B[0m     \u001B[38;5;66;03m# Cache the logits to use for crossentropy loss.\u001B[39;00m\n\u001B[1;32m   5917\u001B[0m     output\u001B[38;5;241m.\u001B[39m_keras_logits \u001B[38;5;241m=\u001B[39m x\n",
      "\u001B[0;31mUnknownError\u001B[0m: Exception encountered when calling layer 'output' (type Dense).\n\n{{function_node __wrapped__Sigmoid_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sigmoid] name: \n\nCall arguments received by layer 'output' (type Dense):\n  • inputs=tf.Tensor(shape=(4, 200), dtype=float32)"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "BATCH = int(len(X_train)/10)\n",
    "\n",
    "print('Train...')\n",
    "model_1.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=300,\n",
    "          validation_split=0.15,\n",
    "          shuffle=True,\n",
    "          callbacks=[es]\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T20:11:14.554947300Z",
     "start_time": "2024-02-04T20:10:59.561563300Z"
    }
   },
   "id": "3b8a1b178414e230",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predict= model_1.evaluate(x=X_test, y=y_test)\n",
    "\n",
    "print(\"Keras F1\")\n",
    "print(\"ANN-1:\")\n",
    "print(\"Loss:\"+str(predict[0]))\n",
    "print(\"F1:\"+str(predict[1]))\n",
    "print(\"Accuracy:\"+str(predict[2]))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = model_1.predict([X_test], verbose=3)\n",
    "\n",
    "result_1 = f1_score(y_true=y_test.round(), y_pred=y_pred.round(), labels=None, average=\"weighted\")\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "labels=mlb.classes_\n",
    "print(classification_report(y_true=y_test.round(), y_pred=y_pred.round(), target_names=labels))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7ed13e271556326",
   "execution_count": 0
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
